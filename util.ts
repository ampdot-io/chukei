import * as path from "jsr:@std/path";
import * as nodePath from "node:path";
import { gguf } from "npm:@huggingface/gguf";

export function securePath(baseDir: string, userPath: string): string | null {
    /* Generated by Emeri-Sonn-4*/
    // sanitize first
    const clean = userPath.replace(/\.\./g, "");

    // join and normalize
    const fullPath = path.normalize(path.join(baseDir, clean));

    // make sure we're still in the base directory
    if (!fullPath.startsWith(path.normalize(baseDir) + nodePath.sep)) {
        return null; // nice try asshole
    }

    return fullPath;
}

// from https://github.com/ggml-org/ggml/blob/master/docs/gguf.md
// modified to make Version field optional, one of the spec examples is missing
// the Version field and fails to parse with the given regex
const ggufRegex =
    /^(?<BaseName>[A-Za-z0-9\s]*(?:(?:-(?:(?:[A-Za-z\s][A-Za-z0-9\s]*)|(?:[0-9\s]*)))*))-(?:(?<SizeLabel>(?:\d+x)?(?:\d+\.)?\d+[A-Za-z](?:-[A-Za-z]+(\d+\.)?\d+[A-ZaZ]+)?)(?:-(?<FineTune>[A-Za-z0-9\s-]+))?)?(?:-(?:(?<Version>v\d+(?:\.\d+)*)))?(?:-(?<Encoding>(?!LoRA|vocab)[\w_]+))?(?:-(?<Type>LoRA|vocab))?(?:-(?<Shard>\d{5}-of-\d{5}))?\.gguf$/;

export function parseGGUFFilename(filename: string) {
    const match = ggufRegex.exec(filename);
    if (!match) {
        return null;
    }
    const {
        BaseName = null,
        SizeLabel = null,
        FineTune = null,
        Version = "v1.0",
        Encoding = null,
        Type = null,
        Shard = null,
    } = match.groups as { [key: string]: string };
    // normalize casing
    return {
        BaseName: BaseName,
        SizeLabel: SizeLabel?.toUpperCase(),
        FineTune: FineTune,
        Version: Version,
        Encoding: Encoding?.toUpperCase(),
        Type: Type,
        Shard: Shard,
    };
}

const ggufFileTypeToQuantLevel = {
    0: "F32",
    1: "F16",
    2: "Q4_0",
    3: "Q4_1",
    4: "Q4_1_SOME_F16",
    7: "Q8_0",
    8: "Q5_0",
    9: "Q5_1",
    10: "Q2_K",
    11: "Q3_K_S",
    12: "Q3_K_M",
    13: "Q3_K_L",
    14: "Q4_K_S",
    15: "Q4_K_M",
    16: "Q5_K_S",
    17: "Q5_K_M",
    18: "Q6_K",
};

export interface QuantInfo {
    quantType?: string;
    quantLevel?: string;
}

export async function getQuantizationType(
    modelId: string,
    path: string,
): Promise<QuantInfo> {
    const ggufNameData = parseGGUFFilename(path);
    let quantLevel;
    if (ggufNameData == null) {
        const url = `https://huggingface.co/${modelId}/resolve/main/${path}`;
        const fileType =
            ((await gguf(url)).metadata as any)["general.file_type"];
        if (fileType != null) {
            quantLevel = ggufFileTypeToQuantLevel[
                fileType as keyof typeof ggufFileTypeToQuantLevel
            ];
        } else {
            return {};
        }
    } else {
        quantLevel = ggufNameData.Encoding;
    }
    const quantType = path.match(`-(rekaquant|UD)-${quantLevel}`);
    if (quantType != null) {
        return { quantType, quantLevel };
    } else {
        return { quantLevel };
    }
}
